# Canvas3D-LLM Project Plan

## ‚úÖ RESOLVED + üöß IN PROGRESS + üÜï NEW REQUIREMENTS (2025-08-01) 

### Issue-008: Universal Multi-Agent Research System (EXPANDED SCOPE)
**Status**: ‚úÖ **DUPLICATE FIXED** + ‚úÖ **OUTPUT FORMAT** + ‚úÖ **UI ENHANCEMENTS** + üîó **INTEGRATED** + üé® **PERPLEXITY-STYLE UI**  
**Priority**: P0 - COMPLETE: Perplexity-style inline research with multi-agent visibility!  
**File**: `cursor_claudecode_ai/issues/Issue-008-Universal-Multi-Agent-Research.md`

### Issue-009: Comprehensive Multi-Agent Research System Enhancement üîß
**Status**: üöß **IN PROGRESS** - Universal LLM intelligence improvements (NO hardcoded rules)  
**Priority**: P0 - URGENT: Enhance LLM intelligence and system transparency  
**File**: `cursor_claudecode_ai/issues/Issue-009-Comprehensive-Multi-Agent-Enhancement.md`

**üìã Detailed TODO**: Issue contains 25 tasks across 6 phases
- **Phase 0**: Fix Deep Research Output Format (3 tasks) - ‚úÖ COMPLETED
  - ‚úÖ Task 0.1: Implement proper research report structure
  - ‚úÖ Task 0.2: Fix missing agent reasoning display
  - ‚úÖ Task 0.3: Fix aggressive deduplication (0.9 ‚Üí 0.95 threshold)
- **Phase 1**: LLM-based data interpretation (4 tasks) - IN PROGRESS
  - ‚úÖ Task 1.1: Enhanced ExtractionAgent with intelligent context prompting
  - üöß Task 1.2: Improve table understanding through LLM intelligence
  - ‚è≥ Task 1.3: Enhance SynthesisAgent for context understanding
  - ‚è≥ Task 1.4: Test with Tyler's PDF data
- **Phase 2**: Granular LLM call tracking (3 tasks) - PENDING  
- **Phase 3**: Dynamic temperature system (4 tasks) - PENDING
- **Phase 4**: Cursor-style flow redesign (3 tasks) - PENDING
- **Phase 5**: Universal testing & validation (5 tasks) - PENDING

**üéØ Core Principle**: **Universal LLM intelligence, ZERO hardcoded patterns**
```
‚ùå BAD: Hardcoded data type labels [RECORD], [TRAINING]
‚úÖ GOOD: LLM asks "What type of document is this? What do columns mean?"
```

**‚úÖ Task 1.1 Completed**: 
- Removed hardcoded extraction patterns
- Added intelligent context-aware prompting
- Enhanced UI visibility for fallback extraction
- Added batch progress tracking in UI

**üö® Critical Issues Found**:
1. Output is only 4 lines instead of deep research report
2. Missing 3 fastest runs (2.55h, 4.01h, 4.26h) from Tyler's table
3. Extractor & Synthesizer agents show NO reasoning in UI
4. Aggressive deduplication: 56 items ‚Üí 25 ‚Üí 1 item for synthesis
5. No Planning ‚Üí RAG ‚Üí Conclusion flow (Phase 4 needed)

**‚úÖ Phase 0 Completed**:
1. Implemented comprehensive research report format with 5 sections
2. Fixed Extractor reasoning preservation (batch insights + final summary)
3. Added Synthesizer reasoning with detailed progress tracking
4. Adjusted deduplication threshold from 0.9 to 0.95 (preserves more unique data)

**üöß Current Focus**: Task 1.2 - Improve table understanding through LLM intelligence

**‚úÖ COMPLETED - Core Fixes**: 
```
‚ùå Before: completed in 45 minutes - 45 minutes
‚úÖ After:  completed in 45 minutes
```

**üöß IN PROGRESS - Output Format**:
```
‚ùå Current: Found 16 relevant results: ‚Ä¢ Run 2: completed in - 45 minutes ‚Ä¢ No relevant information found...
‚úÖ Target:  Based on the search results, here are the top 3 speed runs: 1. Run 3: Speed optimizations - 45 minutes
```

**üÜï NEW - Research Process Visibility** ‚úÖ **COMPLETED**:
```
‚ùå Before: Research steps sidebar too small (320px), no history, Stage 3 shows as one step
‚úÖ After:  Perplexity-style inline research with detailed 5-agent breakdown, thinking sections, and dynamic scrolling

üìã INLINE REQUIREMENTS (User-Specified):
1. UI in non-expanded mode is clunky (Image 01) ‚Üí SOLVED: Removed sidebar entirely
2. Expanded mode has still 3 steps, detailed log has excellent verbose steps not shown (Image 02) ‚Üí SOLVED: All 5 agent sub-steps now visible inline
3. Better UI like Perplexity (Image 03/04) ‚Üí SOLVED: Perplexity-style inline display
4. Show steps for each turn next to source ‚Üí SOLVED: Integrated steps with sources in cards
5. Dynamic scrolling interface (user can scroll) ‚Üí SOLVED: No expand/collapse needed
6. No longer need expand/non-expand mode ‚Üí SOLVED: Single flowing interface
```

**Technical Scope Completed**:
- ‚úÖ Smart time formatting and LLM artifact cleaning
- ‚úÖ Enhanced query detection and content filtering  
- ‚úÖ Clean ranked output testing
- ‚úÖ Perplexity-style inline research display
- ‚úÖ Chat-wise research step persistence via localStorage
- ‚úÖ Multi-agent sub-step breakdown (5 detailed stages with thinking)
- ‚úÖ Agent reasoning visibility with collapsible sections
- ‚úÖ Source integration and expandable excerpts
- ‚úÖ Progress tracking and real-time updates
- ‚úÖ Color-coded agent types with icons
- ‚úÖ Full-width chat interface (no sidebar needed)

### ‚úÖ COMPLETED P0 TODO List for Issue-008:

1. **‚úÖ P0: Investigate SynthesisAgent.ts** - Found line 86 blindly appending time values
2. **‚úÖ P0: Analyze ExtractionAgent.ts** - Confirmed it stores both content AND separate time fields
3. **‚úÖ P0: Identify duplicate logic** - Located in SynthesisAgent `${content} - ${value}` formatting
4. **‚úÖ P0: Implement content check** - Added `formatWithTime()` method with smart logic
5. **‚úÖ P0: Add time parsing logic** - Implemented regex checks for existing time patterns
6. **‚úÖ P0: Test duplicate fix** - Verified: "completed in 45 minutes" (no duplicates)
7. **‚úÖ P0: Fix query type detection** - Enhanced ranking detection for "top 3" queries
8. **‚úÖ P0: Filter irrelevant responses** - Remove "no information found" entries  
9. **‚úÖ P0: Clean LLM artifacts** - Remove "Okay, let me see" type responses
10. **üöß P0: Test output format** - Verify clean "top 3 speed runs" format
11. **üÜï P0: Full-screen research viewer** - Create modal/drawer expansion from sidebar
12. **üÜï P0: Chat history persistence** - Maintain separate research steps per chat session
13. **üÜï P0: Multi-agent sub-steps** - Break Stage 3 into 5 detailed agent processes
14. **üÜï P1: Research navigation** - Add controls to scroll through previous sessions
15. **üÜï P1: Progress indicators** - Show timing and progress for each step/sub-step
16. **üÜï P1: Agent reasoning display** - Show decision-making process in each sub-step
17. **üÜï P1: Step-source mapping** - Connect each step to its sources for traceability
18. **üÜï P1: Timeline view** - Chronological research process with duration insights
19. **P2: Verify all formats** - Test fix works for minutes, hours, seconds, etc.
20. **P2: Resume testing** - Continue multi-agent testing with other domains

---

# Deep Research Component Critical Fixes Plan

## Issue Analysis (2025-07-21) - URGENT

### Critical Problems Identified:

1. **React Key Duplication Still Occurring** üö®
   - Same research step ID appearing multiple times: `analysis_1754064717413_1_0f8c9e4c`
   - Logs show: "Step update" ‚Üí "Adding new step" for SAME ID
   - Root cause: Race condition in useResearch hook step management

2. **Poor Research Output Quality** üö®
   - Malformed text: "Chucnk clraely says 7.51 but such timing wree never shown"
   - Incorrect context synthesis
   - RAG retrieval producing irrelevant/corrupted results

### Root Cause Analysis:

**Key Duplication Issue**:
```typescript
// useResearch.ts lines 940-949
const existingStep = existingSteps.find(s => s.id === step.id);
if (!existingStep) {
  researchStepsState.addStep(step);  // Called multiple times!
} else {
  researchStepsState.updateStep(step.id, step);
}
```
- `onStepUpdate` callback fires multiple times rapidly
- State updates are async, causing race conditions
- Same step gets added multiple times before state updates

**Research Quality Issue**:
- RAG retrieval returning corrupted/irrelevant chunks
- Synthesis logic producing malformed output
- Context assembly not filtering properly

## Solution Plan:

### Phase 1: Fix Race Condition (CRITICAL)
- Implement step deduplication at component level
- Add step ID tracking to prevent duplicate additions
- Fix useResearchSteps state management

### Phase 2: Improve Research Quality (HIGH)
- Fix RAG chunk retrieval and filtering
- Improve synthesis prompt templates
- Add output validation and cleanup

### Phase 3: Testing & Validation
- Test rapid research queries
- Validate no React console errors
- Verify research output quality

## Todo List:
1. ‚úÖ **fix-race-condition-010**: Implement step deduplication in useResearch hook - COMPLETED
2. ‚úÖ **fix-research-quality-011**: Improve RAG retrieval and synthesis quality - COMPLETED
3. ‚úÖ **add-output-validation-012**: Add research output validation and cleanup - COMPLETED
4. ‚úÖ **comprehensive-testing-013**: Test all fixes end-to-end - COMPLETED

## Files Modified:
- ‚úÖ `src/components/DeepResearch/hooks/useResearch.ts` - Race condition fixed
- ‚úÖ `src/lib/ResearchOrchestrator.ts` - Synthesis quality improved
- ‚úÖ `src/components/DeepResearch/components/ResearchSteps.tsx` - Rendering safeguards added

## Success Criteria:
- ‚úÖ Zero React key duplication console errors
- ‚úÖ Clean, accurate research output
- ‚úÖ No malformed text or irrelevant results
- ‚úÖ Smooth research flow without UI glitches
- ‚úÖ Proper step state management

## Implementation Completed:
**‚úÖ Race Condition Fixed**: Set-based step deduplication with processedStepIds tracker
**‚úÖ Research Quality Enhanced**: Clean excerpt generation, text validation, typo fixes
**‚úÖ Output Validation Added**: LLM response cleanup, artifact removal, format validation
**‚úÖ Rendering Safeguards**: Component-level deduplication and unique key generation

## Critical Fixes Applied:
1. **Step Deduplication**: `processedStepIds.current` Set tracker prevents duplicate processing
2. **Excerpt Cleaning**: Smart word-boundary truncation, whitespace normalization  
3. **Text Validation**: Regex-based cleanup of common typos and artifacts
4. **Synthesis Enhancement**: Better context assembly, source filtering
5. **Rendering Protection**: Component-level deduplication and unique React keys
6. **LLM JSON Parsing**: Robust bracket-matching parser with graceful fallback strategy

## Latest Fix: Research Synthesis Quality Issues
**Problem**: Despite finding 15 RAG sources, synthesis output was generic: "no information provided about Tyler Romer's logs"
**Root Cause**: Aggressive text cleaning was destroying technical data (performance numbers, timing, etc.)

**Solution Applied**:
1. **‚ö†Ô∏è CRITICAL**: Removed aggressive regex `[^\w\s\.\,\!\?\-\(\)]` that was destroying:
   - Performance numbers (7.51 ‚Üí "7 51")
   - Technical specs, URLs, timing data
   - All special characters needed for technical content

2. **Enhanced Synthesis Prompt**: New prompt specifically instructs LLM to:
   - Extract EXACT performance data and technical values
   - Quote directly from sources with specific numbers
   - Preserve all technical details and metrics
   - Only say "no information" if data truly doesn't exist

3. **Minimal Text Cleanup**: Now only fixes obvious typos, preserves:
   - Numbers with decimals, technical identifiers
   - Line formatting and structure
   - URLs, timestamps, performance metrics

4. **Debug Logging**: Added source content inspection to verify what data reaches synthesis

**Expected Result**: Tyler's nanogpt speed run data should now be properly extracted and presented with exact timing/performance numbers.

## CRITICAL Follow-up Fix: LLM Planning & JSON Parsing ‚úÖ 
**Problem**: LLM outputting `<think>` tags instead of required JSON format
**Root Cause**: JSON parser couldn't handle `<think>` tags + JSON combination

**Solution Applied**:
1. **Enhanced JSON Parser**: Now extracts JSON after `</think>` tags properly
2. **Preserved LLM Transparency**: `<think>` tags kept for debugging visibility
3. **Multi-strategy Parsing**: Robust JSON extraction with fallbacks
4. **Reverted Query Expansion**: Removed broken query expansion (15‚Üí0 results)

**Status**: ‚úÖ FIXED - JSON parsing works, RAG finds 15 sources, research proceeds

## CURRENT CRITICAL ISSUE: Synthesis Stage Producing Garbage üö®
**Problem**: Despite finding 15 relevant sources, synthesis output is repetitive garbage:
- "Run 1. Keller Jordan maintains a leaderboard here Keller Jordan maintains a leaderboard here..."
- No actual Tyler speed run data extraction

**Root Cause Analysis**:
1. **LLM Model Too Small**: qwen3:0.6b overwhelmed by complex synthesis task
2. **Synthesis Prompt Too Complex**: 3957 characters too much for small model  
3. **Too Many Sources**: 15 RAG sources causing information overload
4. **Context Processing Failure**: LLM latching onto meta-text instead of core data

**Current TODO List**:
1. **URGENT: Replace broken synthesis prompt** - Simple direct extraction for Tyler's speed run data
2. **Limit RAG to top 3 sources** - Stop overwhelming small LLM with 15 sources  
3. **Add anti-repetition rules** - Stop "Keller Jordan" garbage loops

**Target**: Extract actual speed run times and performance metrics from Tyler's blog data